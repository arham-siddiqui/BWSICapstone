{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f96ba30-85d4-47aa-b9b2-46796108268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4372d4eb-e810-4770-9258-efd71865796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_file):\n",
    "    \"\"\"Extracts audio features from a given audio file.\"\"\"\n",
    "\n",
    "    y, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Extract features\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=y))\n",
    "    centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr))\n",
    "    rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    rms = np.mean(librosa.feature.rms(y=y))\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr), axis=1)\n",
    "\n",
    "    # Concatenate features\n",
    "    features = np.hstack([zcr, centroid, bandwidth, contrast, rolloff, rms, chroma, mfcc])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74e69fba-ae33-4291-ae6b-31ca55ddf1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_dir = '/Users/terryding/Downloads/Audio Training Data for Auditory Feature 2/Car Honk- 1'\n",
    "fingerprints = []\n",
    "labels = []\n",
    "for file_name in os.listdir(sound_dir):\n",
    "    labels.append([1,0,0,0,0,0,0])\n",
    "    audio_file_path = os.path.join(sound_dir, file_name)\n",
    "    \n",
    "    #audio_file_name = os.path.basename(audio_file_path)\n",
    "    #filler = audio_file_name.split('-')\n",
    "    #identifier_num = int(numbers[1])\n",
    "    #class_label = num_class_mapping[identifier_num]\n",
    "    #getting the class from the label \n",
    "    \n",
    "    features = extract_features(audio_file_path)\n",
    "    fingerprints.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ba84796-8477-41c1-8690-032ac8d3d6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/week4/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "sound_dir = '/Users/terryding/Downloads/Audio Training Data for Auditory Feature 2/Dog Barking- 3'\n",
    "for file_name in os.listdir(sound_dir):\n",
    "    labels.append([0,1,0,0,0,0,0])\n",
    "    audio_file_path = os.path.join(sound_dir, file_name)\n",
    "    \n",
    "    #audio_file_name = os.path.basename(audio_file_path)\n",
    "    #filler = audio_file_name.split('-')\n",
    "    #identifier_num = int(numbers[1])\n",
    "    #class_label = num_class_mapping[identifier_num]\n",
    "    #getting the class from the label \n",
    "    \n",
    "    features = extract_features(audio_file_path)\n",
    "    fingerprints.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91423397-69b7-496c-b170-046241bfe5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_dir = '/Users/terryding/Downloads/Audio Training Data for Auditory Feature 2/Drilling- 4'\n",
    "for file_name in os.listdir(sound_dir):\n",
    "    labels.append([0,0,1,0,0,0,0])\n",
    "    audio_file_path = os.path.join(sound_dir, file_name)\n",
    "    \n",
    "    #audio_file_name = os.path.basename(audio_file_path)\n",
    "    #filler = audio_file_name.split('-')\n",
    "    #identifier_num = int(numbers[1])\n",
    "    #class_label = num_class_mapping[identifier_num]\n",
    "    #getting the class from the label \n",
    "    \n",
    "    features = extract_features(audio_file_path)\n",
    "    fingerprints.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e85b129-b9fa-451b-8a05-c0303f99a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_dir = '/Users/terryding/Downloads/Audio Training Data for Auditory Feature 2/Engine Idling- 5'\n",
    "for file_name in os.listdir(sound_dir):\n",
    "    labels.append([0,0,0,1,0,0,0])\n",
    "    audio_file_path = os.path.join(sound_dir, file_name)\n",
    "    \n",
    "    #audio_file_name = os.path.basename(audio_file_path)\n",
    "    #filler = audio_file_name.split('-')\n",
    "    #identifier_num = int(numbers[1])\n",
    "    #class_label = num_class_mapping[identifier_num]\n",
    "    #getting the class from the label \n",
    "    \n",
    "    features = extract_features(audio_file_path)\n",
    "    fingerprints.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85ca4fab-6aca-43c2-9cf9-a5c073541f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_dir = '/Users/terryding/Downloads/Audio Training Data for Auditory Feature 2/Jackhammer- 7'\n",
    "for file_name in os.listdir(sound_dir):\n",
    "    labels.append([0,0,0,0,1,0,0])\n",
    "    audio_file_path = os.path.join(sound_dir, file_name)\n",
    "    \n",
    "    #audio_file_name = os.path.basename(audio_file_path)\n",
    "    #filler = audio_file_name.split('-')\n",
    "    #identifier_num = int(numbers[1])\n",
    "    #class_label = num_class_mapping[identifier_num]\n",
    "    #getting the class from the label \n",
    "    \n",
    "    features = extract_features(audio_file_path)\n",
    "    fingerprints.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba817335-8fb1-4b82-879a-917aed644ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_dir = '/Users/terryding/Downloads/Audio Training Data for Auditory Feature 2/Siren- 8'\n",
    "for file_name in os.listdir(sound_dir):\n",
    "    labels.append([0,0,0,0,0,1,0])\n",
    "    audio_file_path = os.path.join(sound_dir, file_name)\n",
    "    \n",
    "    #audio_file_name = os.path.basename(audio_file_path)\n",
    "    #filler = audio_file_name.split('-')\n",
    "    #identifier_num = int(numbers[1])\n",
    "    #class_label = num_class_mapping[identifier_num]\n",
    "    #getting the class from the label \n",
    "    \n",
    "    features = extract_features(audio_file_path)\n",
    "    fingerprints.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbd647fa-c624-4f92-b8a7-061d40a50ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_dir = '/Users/terryding/Downloads/Audio Training Data for Auditory Feature 2/Violence- 6'\n",
    "for file_name in os.listdir(sound_dir):\n",
    "    labels.append([0,0,0,0,0,0,1])\n",
    "    audio_file_path = os.path.join(sound_dir, file_name)\n",
    "    \n",
    "    #audio_file_name = os.path.basename(audio_file_path)\n",
    "    #filler = audio_file_name.split('-')\n",
    "    #identifier_num = int(numbers[1])\n",
    "    #class_label = num_class_mapping[identifier_num]\n",
    "    #getting the class from the label \n",
    "    \n",
    "    features = extract_features(audio_file_path)\n",
    "    fingerprints.append(features)\n",
    "\n",
    "#fingerprints = np.array(fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23965311-ad6f-47b2-a5bb-f28fcb487289",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(fingerprints, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9be5b917-9755-4877-8163-dbc1c7113537",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32e5fb3d-64f4-41c1-9ca9-5fc8117b2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape = (8,32)),\n",
    "    Dense(512/2, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512/2, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f226cc0-ebaa-4075-ba65-ac4509b28a49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})'})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/week4/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/week4/lib/python3.8/site-packages/keras/src/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1102\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m     )\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1115\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})'})"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdf139-b054-48fc-b092-d92c85381bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
